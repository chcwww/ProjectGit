{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMPIl6wRLUOshXntff4qCqF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"oPG_wtH-YRCI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680677304825,"user_tz":-480,"elapsed":24775,"user":{"displayName":"Hc c","userId":"00559738803274000756"}},"outputId":"44e5a30b-5a67-4059-9483-ffb571a7aa65"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DWswz0ZrYNp5"},"outputs":[],"source":["import pandas as pd\n","import gc\n","\n","dirThis = '/content/drive/MyDrive/1經濟學/專題/'\n","\n","offers = pd.read_csv(dirThis + 'offers.csv')\n","#transactions = pd.read_csv(r'/content/drive/MyDrive/1經濟學/專題/newdata.csv')\n","trainHistory = pd.read_csv(dirThis + 'trainHistory.csv')\n","testHistory = pd.read_csv(dirThis + 'testHistory.csv')\n","\n","tranDtype = {\n","    'id': 'uint64',\n","    'chain': 'uint16',\n","    'dept': 'uint8',\n","    'category': 'uint16',\n","    'company': 'uint64',\n","    'brand': 'uint32',\n","    'date' : 'object',\n","    'productsize': 'float32',\n","    'productmeasure': 'category',\n","    'purchasequantity': 'int64',\n","    'purchaseamount': 'float32'\n","    }\n","\n","\n","def generateFeature(offers, transactions, trainHistory, testHistory, tidx) :\n","    # import useful package\n","    from datetime import timedelta\n","    from itertools import cycle\n","    import pandas as pd\n","    import numpy as np\n","    import time\n","    import gc\n","    ts = time.time()\n","    # tk = 1\n","    \n","    # get all data & delete those not in transactions\n","    train = trainHistory.drop(columns = ['repeater', 'repeattrips'])\n","    data = pd.concat([train, testHistory], axis=0, ignore_index=True)\n","    use = data[data['id'].isin(transactions['id'])] # (310665, )\n","\n","    del trainHistory, train, testHistory\n","    gc.collect()\n","    \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(get all data) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","    \n","    # put offer information into transactions\n","    of = offers[['offer', 'category', 'company', 'offervalue', 'brand']]\n","    usf = pd.merge(use, of, on='offer')\n","    usf.columns = ['id', 'chain', 'offer', 'market', 'offerdate', 'offercategory', 'offercompany',\n","          'offervalue', 'offerbrand']\n","    tu = usf[['id', 'offer', 'offerdate', 'offercategory', 'offercompany', 'offerbrand']]\n","    nu = pd.merge(tu, transactions, on='id')\n","    \n","    del tu, usf, of, transactions\n","    gc.collect()\n","    \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(put offer information) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","    \n","    # generate time index\n","    date_format = '%Y-%m-%d'\n","    nu['offerdate'] = pd.to_datetime(nu['offerdate'], format = date_format)\n","    # nu['date'] = pd.to_datetime(nu['date'], format = date_format)\n","    nu['daydiff'] = nu['offerdate'] - nu['date']\n","    nu['diff_180'] = nu['offerdate'] - timedelta(days = 180)\n","    nu['diff_150'] = nu['offerdate'] - timedelta(days = 150)\n","    nu['diff_120'] = nu['offerdate'] - timedelta(days = 120)\n","    nu['diff_90'] = nu['offerdate'] - timedelta(days = 90)\n","    nu['diff_60'] = nu['offerdate'] - timedelta(days = 60)\n","    nu['diff_30'] = nu['offerdate'] - timedelta(days = 30)\n","    \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate time index) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","    \n","    # put offervalue\n","    of1 = offers[['offer', 'offervalue']]\n","    use = pd.merge(use, of1, on='offer')\n","    \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(put offervalue) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","    \n","    # generate total\n","    group = nu.groupby(['id'])\n","    \n","    test = group['chain'].count().reset_index()\n","    test.columns = ['id', 'buy_total_freq']\n","    use = pd.merge(use, test, on='id')\n","    \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate total freq) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","    \n","    test = group['purchaseamount'].sum().reset_index()\n","    test.columns = ['id', 'buy_total_amount']\n","    use = pd.merge(use, test, on='id')\n","    \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate total amount) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","    \n","    test = group['purchaseamount'].mean().reset_index()\n","    test.columns = ['id', 'buy_total_avgamount']\n","    use = pd.merge(use, test, on='id')\n","    \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate total avg) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","    \n","    test = group['purchasequantity'].sum().reset_index()\n","    test.columns = ['id', 'buy_total_quantity']\n","    use = pd.merge(use, test, on='id')\n","    \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate total quan) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","    \n","    test = group['daydiff'].min().reset_index()\n","    test.columns = ['id', 'buy_total_daydiff']\n","    use = pd.merge(use, test, on='id')\n","    \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate total) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","    \n","    \n","    day = np.linspace(30, 180, 6, endpoint=True).astype(int).astype(str)\n","    \n","    for i in day :\n","      daa = 'diff_' + i\n","      nu['ascom'] = nu['date'] >= nu[daa]\n","    \n","      name = 'buy_total_amount_' + i\n","      var = 'purchaseamount'\n","    \n","      group = nu.groupby(['id', 'ascom'])\n","      test = group[var].sum().reset_index()\n","      test.columns = ['id', 'ascom', name]\n","      use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","    \n","      # te = time.time()\n","      # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate day amount) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","      # tk+=1\n","    \n","      name = 'buy_total_quantity_' + i\n","      var = 'purchasequantity'\n","    \n","      group = nu.groupby(['id', 'ascom'])\n","      test = group[var].sum().reset_index()\n","      test.columns = ['id', 'ascom', name]\n","      use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","    \n","      # te = time.time()\n","      # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate day quan) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","      # tk+=1\n","    \n","      name = 'buy_total_freq_' + i\n","      var = 'purchaseamount'\n","    \n","      group = nu.groupby(['id', 'ascom'])\n","      test = group['chain'].count().reset_index()\n","      test.columns = ['id', 'ascom', name]\n","      use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","    \n","      # te = time.time()\n","      # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate day) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","      # tk+=1\n","    \n","    # generate company & brand & category\n","    mea = ['company', 'brand', 'category']\n","    \n","    for i in mea :\n","      nu['ascom'] = nu[i] == nu['offer' + i]\n","      group = nu.groupby(['id', 'ascom'])\n","    \n","      test = group['chain'].count().reset_index()\n","      test.columns = ['id', 'ascom', 'buy_'+i+'_freq']\n","      use = pd.merge(use, test[test['ascom']][['id', 'buy_'+i+'_freq']], on='id', how = 'outer')\n","    \n","      # te = time.time()\n","      # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate other freq) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","      # tk+=1\n","    \n","      test = group['purchaseamount'].sum().reset_index()\n","      test.columns = ['id', 'ascom', 'buy_'+i+'_amount']\n","      use = pd.merge(use, test[test['ascom']][['id', 'buy_'+i+'_amount']], on='id', how = 'outer')\n","    \n","      # te = time.time()\n","      # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate other amount) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","      # tk+=1\n","    \n","      test = group['purchaseamount'].mean().reset_index()\n","      test.columns = ['id', 'ascom', 'buy_'+i+'_avgamount']\n","      use = pd.merge(use, test[test['ascom']][['id', 'buy_'+i+'_avgamount']], on='id', how = 'outer')\n","    \n","      # te = time.time()\n","      # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate other avg) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","      # tk+=1\n","    \n","      test = group['purchasequantity'].sum().reset_index()\n","      test.columns = ['id', 'ascom', 'buy_'+i+'_quantity']\n","      use = pd.merge(use, test[test['ascom']][['id', 'buy_'+i+'_quantity']], on='id', how = 'outer')\n","    \n","      # te = time.time()\n","      # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate other quan) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","      # tk+=1\n","    \n","      test = group['daydiff'].min().reset_index()\n","      test.columns = ['id', 'ascom', 'buy_'+i+'_daydiff']\n","      use = pd.merge(use, test[test['ascom']][['id', 'buy_'+i+'_daydiff']], on='id', how = 'outer')\n","    \n","      # te = time.time()\n","      # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate other) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","      # tk+=1\n","    \n","    \n","    for i, j in zip(day, cycle(mea)) :\n","      daa = 'diff_' + i\n","      nu['ascom'] = ((nu['date'] >= nu[daa]) & (nu[j] == nu['offer' + j]))\n","    \n","      name = 'buy_'+j+'_amount_' + i\n","      var = 'purchaseamount'\n","    \n","      group = nu.groupby(['id', 'ascom'])\n","      test = group[var].sum().reset_index()\n","      test.columns = ['id', 'ascom', name]\n","      use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","    \n","      # te = time.time()\n","      # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate other day amount) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","      # tk+=1\n","    \n","      name = 'buy_'+j+'_quantity_' + i\n","      var = 'purchasequantity'\n","    \n","      group = nu.groupby(['id', 'ascom'])\n","      test = group[var].sum().reset_index()\n","      test.columns = ['id', 'ascom', name]\n","      use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","    \n","      # te = time.time()\n","      # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate other day quan) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","      # tk+=1\n","    \n","      name = 'buy_'+j+'_freq_' + i\n","      var = 'purchaseamount'\n","    \n","      group = nu.groupby(['id', 'ascom'])\n","      test = group['chain'].count().reset_index()\n","      test.columns = ['id', 'ascom', name]\n","      use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","    \n","      # te = time.time()\n","      # # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate other day) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","      # # tk+=1\n","    \n","    # generate not buy index\n","    nu['ascom'] = (nu['company'] == nu['offercompany']) & (nu['brand'] == nu['offerbrand']) & (nu['category'] == nu['offercategory'])\n","    group = nu.groupby(['id', 'ascom'])\n","    \n","    name1 = 'buy_company_brand_category'\n","    name = name1 + '_freq'\n","    \n","    test = group['chain'].count().reset_index()\n","    test.columns = ['id', 'ascom', name]\n","    use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","    use['not_' + name1] = (use[name] > 0) != True\n","    \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate not buy) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","    \n","    nu['ascom'] = (nu['company'] == nu['offercompany']) & (nu['brand'] == nu['offerbrand'])\n","    group = nu.groupby(['id', 'ascom'])\n","    \n","    name1 = 'buy_company_brand'\n","    name = name1 + '_freq'\n","    \n","    test = group['chain'].count().reset_index()\n","    test.columns = ['id', 'ascom', name]\n","    use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","    use['not_' + name1] = (use[name] > 0) != True\n","    \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate not buy) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","    \n","    nu['ascom'] = (nu['company'] == nu['offercompany']) & (nu['category'] == nu['offercategory'])\n","    group = nu.groupby(['id', 'ascom'])\n","    \n","    name1 = 'buy_company_category'\n","    name = name1 + '_freq'\n","    \n","    test = group['chain'].count().reset_index()\n","    test.columns = ['id', 'ascom', name]\n","    use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","    use['not_' + name1] = (use[name] > 0) != True\n","    \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate not buy) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","    \n","    nu['ascom'] = (nu['brand'] == nu['offerbrand']) & (nu['category'] == nu['offercategory'])\n","    group = nu.groupby(['id', 'ascom'])\n","    \n","    name1 = 'buy_brand_category'\n","    name = name1 + '_freq'\n","    \n","    test = group['chain'].count().reset_index()\n","    test.columns = ['id', 'ascom', name]\n","    use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","    use['not_' + name1] = (use[name] > 0) != True\n","\n","    del test, group\n","    gc.collect()\n","    \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate not buy) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","    \n","    use['not_buy_company'] = (use['buy_company_freq'] > 0) != True\n","    use['not_buy_brand'] = (use['buy_brand_freq'] > 0) != True\n","    use['not_buy_category'] = (use['buy_category_freq'] > 0) != True\n","\n","    del nu\n","    gc.collect()\n","    \n","    # handle na problem\n","    dayVar = ['buy_company_daydiff', 'buy_brand_daydiff', 'buy_category_daydiff', 'buy_total_daydiff']\n","    use1 = use[dayVar]\n","    use.drop(columns = dayVar, inplace = True)\n","    use = use.fillna(0)\n","    use1 = use1.fillna(timedelta(0))\n","    use[dayVar] = use1\n","\n","    del use1\n","    gc.collect()\n","    \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(handle na problem) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","    \n","    # transform date type into int\n","    for i in use.columns[range(69, 73)] :\n","      use[i] = use[i].astype('str').apply(lambda x:x[:-5]).astype('int32')\n","    \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(transform date type) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","    \n","    # transform bool type into int\n","    for i in use.columns :\n","      if(use[i].dtypes == 'bool') :\n","        use[i] = use[i].apply(int)\n","    \n","    te = time.time()\n","    print('Inner -', str(tidx) + ' (generate feature) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    \n","    return use\n","\n","\n","def find_index(data_col, val):\n","    val_list = []\n","    \n","    val_list.append(val)\n","    val_list.append(\"end\")\n","\n","    index = data_col.isin(val_list).idxmax()\n","    \n","    return index\n","\n","\n","# =============================================================================\n","# Start Generate\n","# =============================================================================\n","\n","import time\n","t1 = time.time()\n","\n","to = 1\n","idx = 1\n","bc = True\n","row = 30000000\n","end = 349655789\n","Start = []\n","End = []\n","\n","while(bc) :\n","    tm = 1\n","    \n","    t2 = time.time()\n","\n","    if(end+1-idx <= row) :\n","      bc = False\n","      row = end+1-idx\n","      t2 = time.time()\n","      print('Stage -', str(to) + ' of ' + '(LASTTT) -> time elapsed: ' + str(round(t2-t1, 2)) + ' seconds' \\\n","            + '\\n\\nStart : ' + str(idx) + ' End : ' + str(idx+row-1) + '\\n')\n","      tm+=1\n","\n","    print('\\nStage -', str(to) + ' of ' + str(tm) + '(start) -> time elapsed: ' + str(round(t2-t1, 2)) + ' seconds')\n","    tm+=1\n","    \n","    # from dask import dataframe as dd\n","    transactions = pd.read_csv(\n","        dirThis + 'transactions.csv', \n","        names=['id', 'chain', 'dept', 'category', 'company', 'brand', 'date', \\\n","               'productsize', 'productmeasure', 'purchasequantity', 'purchaseamount'],\n","        dtype = tranDtype,\n","        nrows = row,\n","        parse_dates=['date'],\n","        infer_datetime_format=True,\n","        skiprows = idx,\n","        # engine = \"pyarrow\",\n","        # engine = \"python-fwf\",\n","        engine = \"c\"\n","        # blocksize=64000000 # = 64 Mb chunks\n","    )\n","    \n","    if(bc) :\n","        idx1 = find_index(transactions['id'], int(transactions['id'].loc[len(transactions['id']) - 1]))\n","        \n","        del transactions\n","        gc.collect()\n","        \n","        t2 = time.time()\n","        print('Stage -', str(to) + ' of ' + str(tm) + '(read data) -> time elapsed: ' + str(round(t2-t1, 2)) + ' seconds')\n","        tm+=1\n","        \n","        transactions = pd.read_csv(\n","            dirThis + 'transactions.csv', \n","            names=['id', 'chain', 'dept', 'category', 'company', 'brand', 'date', \\\n","                    'productsize', 'productmeasure', 'purchasequantity', 'purchaseamount'],\n","            dtype = tranDtype,\n","            nrows = idx1,\n","            parse_dates=['date'],\n","            infer_datetime_format=True,\n","            skiprows = idx,\n","            # engine = \"pyarrow\",\n","            # engine = \"python-fwf\",\n","            engine = \"c\"\n","            # blocksize=64000000 # = 64 Mb chunks\n","        )\n","    \n","    t2 = time.time()\n","    print('Stage -', str(to) + ' of ' + str(tm) + '(reRead data) -> time elapsed: ' + str(round(t2-t1, 2)) + ' seconds' \\\n","          + '\\n\\nStart : ' + str(idx) + ' End : ' + str(idx+idx1-1) + '\\n')\n","    tm+=1\n","\n","    Start.append(idx)\n","    End.append(idx+idx1-1)\n","    \n","    idx += idx1\n","      \n","    use = generateFeature(offers, transactions, trainHistory, testHistory, to)\n","\n","    del transactions\n","    gc.collect()\n","    \n","    t2 = time.time()\n","    print('Stage -', str(to) + ' of ' + str(tm) + '(generate) -> time elapsed: ' + str(round(t2-t1, 2)) + ' seconds')\n","    tm+=1\n","    \n","    use.to_csv(dirThis + '/split/split' + str(to) + '.csv')\n","    \n","    \n","    del use\n","    \n","    t2 = time.time()\n","    print('Stage -', str(to) + ' of ' + str(tm) + '(ouput) -> time elapsed: ' + str(round(t2-t1, 2)) + ' seconds\\n')\n","    gc.collect()\n","    tm+=1\n","    to+=1\n","\n","print(\"Finish!!!!!\")"]},{"cell_type":"code","source":["import pandas as pd\n","import time\n","\n","tranDtype = {\n","    'id': 'uint64',\n","    'chain': 'uint16',\n","    'dept': 'uint8',\n","    'category': 'uint16',\n","    'company': 'uint64',\n","    'brand': 'uint32',\n","    'date' : 'object',\n","    'productsize': 'float32',\n","    'productmeasure': 'category',\n","    'purchasequantity': 'int64',\n","    'purchaseamount': 'float32'\n","    }\n","\n","dirThis = '/content/drive/MyDrive/1經濟學/專題/'\n","\n","# offers = pd.read_csv(dirThis + 'offers.csv')"],"metadata":{"id":"yIyoGQ2p4Uof","executionInfo":{"status":"ok","timestamp":1680676190244,"user_tz":-480,"elapsed":508,"user":{"displayName":"Hc c","userId":"00559738803274000756"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# !pip show pandas\n","# !pip uninstall pandas\n","# !pip install pandas==0.25.3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3-KzJ8wo9SG-","executionInfo":{"status":"ok","timestamp":1680675341970,"user_tz":-480,"elapsed":21179,"user":{"displayName":"Hc c","userId":"00559738803274000756"}},"outputId":"4258a306-3386-4955-fbe0-e0b580717632"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: pandas 2.0.0\n","Uninstalling pandas-2.0.0:\n","  Would remove:\n","    /usr/local/lib/python3.9/dist-packages/pandas-2.0.0.dist-info/*\n","    /usr/local/lib/python3.9/dist-packages/pandas/*\n","Proceed (Y/n)? Y\n","  Successfully uninstalled pandas-2.0.0\n"]}]},{"cell_type":"code","source":["pip install dask toolz cloudpickle"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xbnB4jWUFf4X","executionInfo":{"status":"ok","timestamp":1680676175145,"user_tz":-480,"elapsed":4067,"user":{"displayName":"Hc c","userId":"00559738803274000756"}},"outputId":"c39641f8-d104-4cce-81ad-2948c4819657"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: dask in /usr/local/lib/python3.9/dist-packages (2022.12.1)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.9/dist-packages (0.12.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (2.2.1)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from dask) (8.1.3)\n","Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from dask) (2023.3.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from dask) (23.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from dask) (6.0)\n","Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.9/dist-packages (from dask) (1.3.0)\n","Requirement already satisfied: locket in /usr/local/lib/python3.9/dist-packages (from partd>=0.3.10->dask) (1.0.0)\n"]}]},{"cell_type":"code","source":["import dask.dataframe as dd\n","\n","# df = dd.read_csv(\"large_dataset.csv\")\n"],"metadata":{"id":"Sebl3jBxGOvh","executionInfo":{"status":"ok","timestamp":1680676178503,"user_tz":-480,"elapsed":1271,"user":{"displayName":"Hc c","userId":"00559738803274000756"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# import pandas as pd\n","\n","import dask.dataframe as dd\n","import time\n","\n","dirThis = '/content/drive/MyDrive/1經濟學/專題/'\n","idx = 1\n","row = 15000000\n","\n","t1 = time.time()\n","transactions = dd.read_csv(dirThis + 'newdata.csv', dtype = tranDtype)\n","t2 = time.time()\n","\n","print('time elapsed: ' + str(round(t2-t1, 2)) + ' seconds')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bi46bn4b4kFM","executionInfo":{"status":"ok","timestamp":1680676335916,"user_tz":-480,"elapsed":467,"user":{"displayName":"Hc c","userId":"00559738803274000756"}},"outputId":"da9a5085-2f17-4d27-9960-862098c9bfd1"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["time elapsed: 0.11 seconds\n"]}]},{"cell_type":"code","source":["transactions.info(memory_usage='deep')\n","transactions.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HCK9S0iYHEvK","executionInfo":{"status":"ok","timestamp":1680676357078,"user_tz":-480,"elapsed":19138,"user":{"displayName":"Hc c","userId":"00559738803274000756"}},"outputId":"35a12fa0-8a93-4a87-a065-377c8158bcf5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'dask.dataframe.core.DataFrame'>\n","Columns: 11 entries, id to purchaseamount\n","dtypes: category(1), object(1), float32(2), int64(1), uint16(2), uint32(1), uint64(2), uint8(1)\n","memory usage: 731.9 MB\n"]},{"output_type":"execute_result","data":{"text/plain":["(Delayed('int-79dcb5a1-334a-4857-96dd-d361c5723e6a'), 11)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["pd.DataFrame(transactions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"YgOxYbQaHh9y","executionInfo":{"status":"ok","timestamp":1680676483549,"user_tz":-480,"elapsed":32025,"user":{"displayName":"Hc c","userId":"00559738803274000756"}},"outputId":"76181f66-60d2-4228-9d95-4c317ba07187"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                  0    1   2     3           4      5           6      7   8   \\\n","0              86246  205  99  9909   104538848  15343  2012-03-02   16.0  OZ   \n","1              86246  205  58  5824   108674585  55172  2012-03-02   16.0  OZ   \n","2              86246  205  72  7205   103500030   3830  2012-03-06    4.6  OZ   \n","3              86246  205  55  5558   104154848   5603  2012-03-07    5.8  OZ   \n","4              86246  205  58  5824  1076401474    304  2012-03-14   12.0  OZ   \n","...              ...  ...  ..   ...         ...    ...         ...    ...  ..   \n","15349951  4847628950  166  58  5824  1076401474    304  2013-07-23   12.0  OZ   \n","15349952  4847787712   46  21  2119  1088692686  11473  2013-07-21  128.0  OZ   \n","15349953  4847787712   46  35  3509   103320030    875  2013-07-21   75.0  OZ   \n","15349954  4853598737   46  55  5558   104154848   5603  2013-07-20    5.8  OZ   \n","15349955  4853598737   46  58  5824   104660040   5557  2013-07-20   14.0  OZ   \n","\n","         9     10  \n","0         1  2.49  \n","1         1  3.29  \n","2         1  3.99  \n","3         1  1.25  \n","4         1  4.99  \n","...      ..   ...  \n","15349951  1  5.99  \n","15349952  1  1.99  \n","15349953  2  6.98  \n","15349954  3   3.0  \n","15349955  1  2.79  \n","\n","[15349956 rows x 11 columns]"],"text/html":["\n","  <div id=\"df-c0e7d4bf-5b11-4954-8c71-aa0100c2206f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>86246</td>\n","      <td>205</td>\n","      <td>99</td>\n","      <td>9909</td>\n","      <td>104538848</td>\n","      <td>15343</td>\n","      <td>2012-03-02</td>\n","      <td>16.0</td>\n","      <td>OZ</td>\n","      <td>1</td>\n","      <td>2.49</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>86246</td>\n","      <td>205</td>\n","      <td>58</td>\n","      <td>5824</td>\n","      <td>108674585</td>\n","      <td>55172</td>\n","      <td>2012-03-02</td>\n","      <td>16.0</td>\n","      <td>OZ</td>\n","      <td>1</td>\n","      <td>3.29</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>86246</td>\n","      <td>205</td>\n","      <td>72</td>\n","      <td>7205</td>\n","      <td>103500030</td>\n","      <td>3830</td>\n","      <td>2012-03-06</td>\n","      <td>4.6</td>\n","      <td>OZ</td>\n","      <td>1</td>\n","      <td>3.99</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>86246</td>\n","      <td>205</td>\n","      <td>55</td>\n","      <td>5558</td>\n","      <td>104154848</td>\n","      <td>5603</td>\n","      <td>2012-03-07</td>\n","      <td>5.8</td>\n","      <td>OZ</td>\n","      <td>1</td>\n","      <td>1.25</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>86246</td>\n","      <td>205</td>\n","      <td>58</td>\n","      <td>5824</td>\n","      <td>1076401474</td>\n","      <td>304</td>\n","      <td>2012-03-14</td>\n","      <td>12.0</td>\n","      <td>OZ</td>\n","      <td>1</td>\n","      <td>4.99</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>15349951</th>\n","      <td>4847628950</td>\n","      <td>166</td>\n","      <td>58</td>\n","      <td>5824</td>\n","      <td>1076401474</td>\n","      <td>304</td>\n","      <td>2013-07-23</td>\n","      <td>12.0</td>\n","      <td>OZ</td>\n","      <td>1</td>\n","      <td>5.99</td>\n","    </tr>\n","    <tr>\n","      <th>15349952</th>\n","      <td>4847787712</td>\n","      <td>46</td>\n","      <td>21</td>\n","      <td>2119</td>\n","      <td>1088692686</td>\n","      <td>11473</td>\n","      <td>2013-07-21</td>\n","      <td>128.0</td>\n","      <td>OZ</td>\n","      <td>1</td>\n","      <td>1.99</td>\n","    </tr>\n","    <tr>\n","      <th>15349953</th>\n","      <td>4847787712</td>\n","      <td>46</td>\n","      <td>35</td>\n","      <td>3509</td>\n","      <td>103320030</td>\n","      <td>875</td>\n","      <td>2013-07-21</td>\n","      <td>75.0</td>\n","      <td>OZ</td>\n","      <td>2</td>\n","      <td>6.98</td>\n","    </tr>\n","    <tr>\n","      <th>15349954</th>\n","      <td>4853598737</td>\n","      <td>46</td>\n","      <td>55</td>\n","      <td>5558</td>\n","      <td>104154848</td>\n","      <td>5603</td>\n","      <td>2013-07-20</td>\n","      <td>5.8</td>\n","      <td>OZ</td>\n","      <td>3</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>15349955</th>\n","      <td>4853598737</td>\n","      <td>46</td>\n","      <td>58</td>\n","      <td>5824</td>\n","      <td>104660040</td>\n","      <td>5557</td>\n","      <td>2013-07-20</td>\n","      <td>14.0</td>\n","      <td>OZ</td>\n","      <td>1</td>\n","      <td>2.79</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>15349956 rows × 11 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0e7d4bf-5b11-4954-8c71-aa0100c2206f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c0e7d4bf-5b11-4954-8c71-aa0100c2206f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c0e7d4bf-5b11-4954-8c71-aa0100c2206f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["pd.io.parquet.PyArrowImpl()\n","\n","idx = 1 \n","t1 = time.time()\n","# from dask import dataframe as dd\n","transactions = pd.read_csv(\n","    dirThis + 'transactions.csv', \n","    names=['id', 'chain', 'dept', 'category', 'company', 'brand', 'date', \\\n","           'productsize', 'productmeasure', 'purchasequantity', 'purchaseamount'],\n","    dtype = tranDtype,\n","    nrows = 100000,\n","    parse_dates=['date'],\n","    infer_datetime_format=True,\n","    header = idx\n","    # blocksize=64000000 # = 64 Mb chunks\n",")\n","# transactions = read_single_csv(dirThis + 'transactions.csv', idx)\n","t2 = time.time()\n","\n","print('time elapsed: ' + str(round(t2-t1, 2)) + ' seconds')\n","\n","# pip install modin[ray]\n","\n","import modin.pandas as pd\n","import ray\n","ray.init(runtime_env={'env_vars': {'__MODIN_AUTOIMPORT_PANDAS__': '1'}})\n","\n","import pandas as pd\n","idx = 1000000\n","t1 = time.time()\n","# from dask import dataframe as dd\n","transactions = pd.read_csv(\n","    dirThis + 'transactions.csv', \n","    names=['id', 'chain', 'dept', 'category', 'company', 'brand', 'date', \\\n","           'productsize', 'productmeasure', 'purchasequantity', 'purchaseamount'],\n","    dtype = tranDtype,\n","    nrows = 1000000,\n","    parse_dates=['date'],\n","    infer_datetime_format=True,\n","    skiprows = idx,\n","    # engine = \"pyarrow\",\n","    # engine = \"python-fwf\",\n","    engine = \"pyarrow\"\n","    # blocksize=64000000 # = 64 Mb chunks\n",")\n","# transactions = read_single_csv(dirThis + 'transactions.csv', idx)\n","t2 = time.time()\n","\n","print('time elapsed: ' + str(round(t2-t1, 2)) + ' seconds')\n","\n","pd.io.parquet.get_engine('auto')\n","import pyarrow.parquet"],"metadata":{"id":"-1OjIus_4ENV"},"execution_count":null,"outputs":[]}]}