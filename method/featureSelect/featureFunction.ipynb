{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Project"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36083,"status":"ok","timestamp":1680802083045,"user":{"displayName":"Hc c","userId":"00559738803274000756"},"user_tz":-480},"id":"2gx94fTPAsyy","outputId":"f624a62c-6b17-4508-c889-6ec06e29d7ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OTUUDNeZAzv-"},"outputs":[],"source":["import pandas as pd\n","\n","offers = pd.read_csv(r'/content/drive/MyDrive/1經濟學/專題/offers.csv')\n","transactions = pd.read_csv(r'/content/drive/MyDrive/1經濟學/專題/newdata.csv')\n","trainhistory = pd.read_csv(r'/content/drive/MyDrive/1經濟學/專題/trainHistory.csv')\n","testhistory = pd.read_csv(r'/content/drive/MyDrive/1經濟學/專題/testHistory.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OQ4-pG8zIAXN"},"outputs":[],"source":["# transactions.info(memory_usage='deep')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DFVU6nIEYkS3"},"outputs":[],"source":["tranDtype = {'id': 'uint64',\n"," 'chain': 'uint16',\n"," 'dept': 'uint8',\n"," 'category': 'uint16',\n"," 'company': 'uint64',\n"," 'brand': 'uint32',\n","#  'date' : 'object',\n"," 'productsize': 'float32',\n"," 'productmeasure': 'category',\n"," 'purchasequantity': 'int64',\n"," 'purchaseamount': 'float32'}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TQ7hbkDgcSK7"},"outputs":[],"source":["# tranDtype1 = {\n","#  'category': 'uint16',\n","#  'brand': 'uint32',\n","#  'date' : 'category',\n","#  'productsize': 'float32',\n","#  'purchasequantity': 'int64',\n","#  'purchaseamount': 'float32'\n","#  }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vAoOA4VOGo39"},"outputs":[],"source":["import pandas as pd\n","# from dask import dataframe as dd\n","transactions = pd.read_csv('/content/drive/MyDrive/1經濟學/專題/transactions.csv', \\\n","    # names=['id', 'chain', 'dept', 'category', 'company', 'brand', 'date', \\\n","    # 'productsize', 'productmeasure', 'purchasequantity', 'purchaseamount'],\n","    dtype = tranDtype,\n","    nrows = 100000,\n","    parse_dates=['date'],\n","    infer_datetime_format=True\n","    # blocksize=64000000 # = 64 Mb chunks\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":503,"status":"ok","timestamp":1680626215745,"user":{"displayName":"Hc c","userId":"00559738803274000756"},"user_tz":-480},"id":"j5AYZZXTCrFy","outputId":"3f2e076f-d105-4b59-8055-3f359ffc32d5"},"outputs":[{"data":{"text/plain":["(10000, 11)"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["transactions.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GSdlrYwtE78W"},"outputs":[],"source":["def find_index(data_col, val):\n","    val_list = []\n","    \n","    val_list.append(val)\n","    val_list.append(\"end\")\n","\n","    index = data_col.isin(val_list).idxmax()\n","    \n","    return index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nycDReWmEY9F"},"outputs":[],"source":["idx = find_index(transactions['id'], int(transactions['id'].loc[len(transactions['id']) - 1])) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":549,"status":"ok","timestamp":1680625464901,"user":{"displayName":"Hc c","userId":"00559738803274000756"},"user_tz":-480},"id":"AbsLqkoJFN50","outputId":"3cd4f89d-31d0-485a-b0a0-60111e280060"},"outputs":[{"data":{"text/plain":["126082871"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["transactions['id'].loc[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2539,"status":"ok","timestamp":1680782652138,"user":{"displayName":"Hc c","userId":"00559738803274000756"},"user_tz":-480},"id":"cFp6MZLsJkUH","outputId":"8b1edb27-4401-4caf-9f61-d86c9026bd03"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 15349956 entries, 0 to 15349955\n","Data columns (total 11 columns):\n"," #   Column            Dtype  \n","---  ------            -----  \n"," 0   id                int64  \n"," 1   chain             int64  \n"," 2   dept              int64  \n"," 3   category          int64  \n"," 4   company           int64  \n"," 5   brand             int64  \n"," 6   date              object \n"," 7   productsize       float64\n"," 8   productmeasure    object \n"," 9   purchasequantity  int64  \n"," 10  purchaseamount    float64\n","dtypes: float64(2), int64(7), object(2)\n","memory usage: 2.8 GB\n"]}],"source":["transactions.info(memory_usage='deep')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ovZxIY3DhCk"},"outputs":[],"source":["# import gzip\n","# with gzip.open('/content/drive/MyDrive/1經濟學/專題/transactions.csv.gz', 'rb') as f:\n","#   file_content = f.read()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xov93lgoguMu"},"source":["Feature Function"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1681119465023,"user":{"displayName":"Hc c","userId":"00559738803274000756"},"user_tz":-480},"id":"NGPqJTbDA-bW"},"outputs":[],"source":["def generateFeature(offers, transactions, trainHistory, testHistory) :\n","# import useful package\n","  from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n","  from datetime import timedelta\n","  from itertools import cycle\n","  import pandas as pd\n","  import numpy as np\n","  import time\n","  import gc\n","  ts = time.time()\n","  # tk = 1\n","  \n","  # get all data & delete those not in transactions\n","  train = trainHistory.drop(columns = ['repeater', 'repeattrips'])\n","  data = pd.concat([train, testHistory], axis=0, ignore_index=True)\n","  use = data[data['id'].isin(transactions['id'])] # (310665, )\n","\n","  # del trainHistory, train, testHistory\n","  gc.collect()\n","  \n","  # te = time.time()\n","  # print('Inner -', str(tidx) + ' of ' + str(tk) + '(get all data) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","  # tk+=1\n","  \n","  # put offer information into transactions\n","  of = offers[['offer', 'category', 'company', 'offervalue', 'brand']]\n","  usf = pd.merge(use, of, on='offer')\n","  usf.columns = ['id', 'chain', 'offer', 'market', 'offerdate', 'offercategory', 'offercompany',\n","        'offervalue', 'offerbrand']\n","  tu = usf[['id', 'offer', 'offerdate', 'offercategory', 'offercompany', 'offerbrand']]\n","  nu = pd.merge(tu, transactions, on='id')\n","  \n","  del tu, usf, of, transactions\n","  gc.collect()\n","  \n","  # te = time.time()\n","  # print('Inner -', str(tidx) + ' of ' + str(tk) + '(put offer information) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","  # tk+=1\n","  \n","  # generate time index\n","  date_format = '%Y-%m-%d'\n","  nu['offerdate'] = pd.to_datetime(nu['offerdate'], format = date_format)\n","  nu['date'] = pd.to_datetime(nu['date'], format = date_format)\n","  nu['daydiff'] = nu['offerdate'] - nu['date']\n","  nu['diff_180'] = nu['offerdate'] - timedelta(days = 180)\n","  nu['diff_150'] = nu['offerdate'] - timedelta(days = 150)\n","  nu['diff_120'] = nu['offerdate'] - timedelta(days = 120)\n","  nu['diff_90'] = nu['offerdate'] - timedelta(days = 90)\n","  nu['diff_60'] = nu['offerdate'] - timedelta(days = 60)\n","  nu['diff_30'] = nu['offerdate'] - timedelta(days = 30)\n","  \n","  # te = time.time()\n","  # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate time index) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","  # tk+=1\n","  \n","  # put offervalue\n","  of1 = offers[['offer', 'offervalue']]\n","  use = pd.merge(use, of1, on='offer')\n","  \n","  # te = time.time()\n","  # print('Inner -', str(tidx) + ' of ' + str(tk) + '(put offervalue) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","  # tk+=1\n","  \n","  # generate total\n","  group = nu.groupby(['id'])\n","  \n","  test = group['chain'].count().reset_index()\n","  test.columns = ['id', 'buy_total_freq']\n","  use = pd.merge(use, test, on='id')\n","  \n","  # te = time.time()\n","  # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate total freq) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","  # tk+=1\n","  \n","  test = group['purchaseamount'].sum().reset_index()\n","  test.columns = ['id', 'buy_total_amount']\n","  use = pd.merge(use, test, on='id')\n","  \n","  # te = time.time()\n","  # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate total amount) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","  # tk+=1\n","  \n","  test = group['purchaseamount'].mean().reset_index()\n","  test.columns = ['id', 'buy_total_avgamount']\n","  use = pd.merge(use, test, on='id')\n","  \n","  # te = time.time()\n","  # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate total avg) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","  # tk+=1\n","  \n","  test = group['purchasequantity'].sum().reset_index()\n","  test.columns = ['id', 'buy_total_quantity']\n","  use = pd.merge(use, test, on='id')\n","  \n","  # te = time.time()\n","  # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate total quan) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","  # tk+=1\n","  \n","  test = group['daydiff'].min().reset_index()\n","  test.columns = ['id', 'buy_total_daydiff']\n","  use = pd.merge(use, test, on='id')\n","  \n","  # te = time.time()\n","  # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate total) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","  # tk+=1\n","  \n","  \n","  day = np.linspace(30, 180, 6, endpoint=True).astype(int).astype(str)\n","  \n","  for i in day :\n","    daa = 'diff_' + i\n","    nu['ascom'] = nu['date'] >= nu[daa]\n","  \n","    name = 'buy_total_amount_' + i\n","    var = 'purchaseamount'\n","  \n","    group = nu.groupby(['id', 'ascom'])\n","    test = group[var].sum().reset_index()\n","    test.columns = ['id', 'ascom', name]\n","    use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","  \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate day amount) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","  \n","    name = 'buy_total_quantity_' + i\n","    var = 'purchasequantity'\n","  \n","    group = nu.groupby(['id', 'ascom'])\n","    test = group[var].sum().reset_index()\n","    test.columns = ['id', 'ascom', name]\n","    use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","  \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate day quan) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","  \n","    name = 'buy_total_freq_' + i\n","    var = 'purchaseamount'\n","  \n","    group = nu.groupby(['id', 'ascom'])\n","    test = group['chain'].count().reset_index()\n","    test.columns = ['id', 'ascom', name]\n","    use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","  \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate day) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","  \n","  # generate company & brand & category\n","  mea = ['company', 'brand', 'category']\n","  day = np.repeat(np.linspace(30, 180, 6, endpoint=True), 3).astype(int).astype(str)\n","  \n","  for i in mea :\n","    nu['ascom'] = nu[i] == nu['offer' + i]\n","    group = nu.groupby(['id', 'ascom'])\n","  \n","    test = group['chain'].count().reset_index()\n","    test.columns = ['id', 'ascom', 'buy_'+i+'_freq']\n","    use = pd.merge(use, test[test['ascom']][['id', 'buy_'+i+'_freq']], on='id', how = 'outer')\n","  \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate other freq) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","  \n","    test = group['purchaseamount'].sum().reset_index()\n","    test.columns = ['id', 'ascom', 'buy_'+i+'_amount']\n","    use = pd.merge(use, test[test['ascom']][['id', 'buy_'+i+'_amount']], on='id', how = 'outer')\n","  \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate other amount) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","  \n","    test = group['purchaseamount'].mean().reset_index()\n","    test.columns = ['id', 'ascom', 'buy_'+i+'_avgamount']\n","    use = pd.merge(use, test[test['ascom']][['id', 'buy_'+i+'_avgamount']], on='id', how = 'outer')\n","  \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate other avg) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","  \n","    test = group['purchasequantity'].sum().reset_index()\n","    test.columns = ['id', 'ascom', 'buy_'+i+'_quantity']\n","    use = pd.merge(use, test[test['ascom']][['id', 'buy_'+i+'_quantity']], on='id', how = 'outer')\n","  \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate other quan) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","  \n","    test = group['daydiff'].min().reset_index()\n","    test.columns = ['id', 'ascom', 'buy_'+i+'_daydiff']\n","    use = pd.merge(use, test[test['ascom']][['id', 'buy_'+i+'_daydiff']], on='id', how = 'outer')\n","  \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate other) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","  \n","  \n","  for i, j in zip(day, cycle(mea)) :\n","    daa = 'diff_' + i\n","    nu['ascom'] = ((nu['date'] >= nu[daa]) & (nu[j] == nu['offer' + j]))\n","  \n","    name = 'buy_'+j+'_amount_' + i\n","    var = 'purchaseamount'\n","  \n","    group = nu.groupby(['id', 'ascom'])\n","    test = group[var].sum().reset_index()\n","    test.columns = ['id', 'ascom', name]\n","    use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","  \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate other day amount) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","  \n","    name = 'buy_'+j+'_quantity_' + i\n","    var = 'purchasequantity'\n","  \n","    group = nu.groupby(['id', 'ascom'])\n","    test = group[var].sum().reset_index()\n","    test.columns = ['id', 'ascom', name]\n","    use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","  \n","    # te = time.time()\n","    # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate other day quan) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # tk+=1\n","  \n","    name = 'buy_'+j+'_freq_' + i\n","    var = 'purchaseamount'\n","  \n","    group = nu.groupby(['id', 'ascom'])\n","    test = group['chain'].count().reset_index()\n","    test.columns = ['id', 'ascom', name]\n","    use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","  \n","    # te = time.time()\n","    # # print('Inner -', str(tidx) + ' of ' + str(tk) + '(generate other day) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","    # # tk+=1\n","  \n","  # generate not buy index\n","  nu['ascom'] = (nu['company'] == nu['offercompany']) & (nu['brand'] == nu['offerbrand']) & (nu['category'] == nu['offercategory'])\n","  group = nu.groupby(['id', 'ascom'])\n","\n","  name1 = 'buy_company_brand_category'\n","  name = name1 + '_freq'\n","\n","  test = group['chain'].count().reset_index()\n","  test.columns = ['id', 'ascom', name]\n","  use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","  new = pd.DataFrame((use[name] > 0) != True)\n","  new.columns = ['not_' + name1]\n","  use = pd.concat([use, new], axis = 1)\n","\n","\n","\n","  nu['ascom'] = (nu['company'] == nu['offercompany']) & (nu['brand'] == nu['offerbrand'])\n","  group = nu.groupby(['id', 'ascom'])\n","\n","  name1 = 'buy_company_brand'\n","  name = name1 + '_freq'\n","\n","  test = group['chain'].count().reset_index()\n","  test.columns = ['id', 'ascom', name]\n","  use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","  new = pd.DataFrame((use[name] > 0) != True)\n","  new.columns = ['not_' + name1]\n","  use = pd.concat([use, new], axis = 1)\n","\n","\n","\n","  nu['ascom'] = (nu['company'] == nu['offercompany']) & (nu['category'] == nu['offercategory'])\n","  group = nu.groupby(['id', 'ascom'])\n","\n","  name1 = 'buy_company_category'\n","  name = name1 + '_freq'\n","\n","  test = group['chain'].count().reset_index()\n","  test.columns = ['id', 'ascom', name]\n","  use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","  new = pd.DataFrame((use[name] > 0) != True)\n","  new.columns = ['not_' + name1]\n","  use = pd.concat([use, new], axis = 1)\n","\n","\n","\n","  nu['ascom'] = (nu['brand'] == nu['offerbrand']) & (nu['category'] == nu['offercategory'])\n","  group = nu.groupby(['id', 'ascom'])\n","\n","  name1 = 'buy_brand_category'\n","  name = name1 + '_freq'\n","\n","  test = group['chain'].count().reset_index()\n","  test.columns = ['id', 'ascom', name]\n","  use = pd.merge(use, test[test['ascom']][['id', name]], on='id', how = 'outer')\n","  new = pd.DataFrame((use[name] > 0) != True)\n","  new.columns = ['not_' + name1]\n","  use = pd.concat([use, new], axis = 1)\n","\n","  del new\n","  gc.collect()\n","\n","  new1 = pd.DataFrame((use['buy_company_freq'] > 0) != True)\n","  new1.columns = ['not_buy_company']\n","  new2 = pd.DataFrame((use['buy_brand_freq'] > 0) != True)\n","  new2.columns = ['not_buy_brand']\n","  new3 = pd.DataFrame((use['buy_category_freq'] > 0) != True)\n","  new3.columns = ['not_buy_category']\n","  use = pd.concat([use, new1, new2, new3], axis = 1)\n","\n","  del new1, new2, new3\n","  gc.collect()\n","\n","  # handle na problem\n","  dayVar = ['buy_company_daydiff', 'buy_brand_daydiff', 'buy_category_daydiff', 'buy_total_daydiff']\n","  use1 = use[dayVar]\n","  use.drop(columns = dayVar, inplace = True)\n","  use = use.fillna(0)\n","  use1 = use1.fillna(timedelta(0))\n","  use = pd.concat([use, use1], axis = 1)\n","\n","  del use1\n","  gc.collect()\n","  \n","  # te = time.time()\n","  # print('Inner -', str(tidx) + ' of ' + str(tk) + '(handle na problem) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","  # tk+=1\n","  \n","  # transform date type into int\n","  for i in use[dayVar] :\n","    use[i] = use[i].astype('str').apply(lambda x:x[:-5]).astype('int32')\n","  \n","  # te = time.time()\n","  # print('Inner -', str(tidx) + ' of ' + str(tk) + '(transform date type) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","  # tk+=1\n","  \n","  # transform bool type into int\n","  for i in use.columns :\n","    if(use[i].dtypes == 'bool') :\n","      use[i] = use[i].apply(int)\n","  \n","  te = time.time()\n","  # print('Inner -', str(tidx) + ' (generate feature) -> time elapsed: ' + str(round(te-ts, 2)) + ' seconds')\n","\n","  # transform into train and test\n","  trainData = use[use['id'].isin(trainHistory['id'])] # (159700,\n","  testData = use[use['id'].isin(testHistory['id'])] # (150965\n","  rep = trainHistory[['id', 'repeater']].copy()\n","  rept = trainHistory[['id', 'repeattrips']].copy()\n","  target = rep[rep['id'].isin(trainData['id'])] # (159700,\n","  targetT = rept[rept['id'].isin(trainData['id'])] # (159700,\n","\n","  # ordinal encode\n","  cod = OrdinalEncoder()\n","  cod = cod.fit(use[['market', 'offer', 'chain']])\n","  use[['market', 'offer', 'chain']] = cod.transform(use[['market', 'offer', 'chain']])\n","  trainEncode = use[use['id'].isin(trainHistory['id'])] # (159700,\n","  testEncode = use[use['id'].isin(testHistory['id'])] # (150965\n","\n","  # encode for target\n","  targetEncode = target.copy()\n","  cod = LabelEncoder()\n","  targetEncode['repeater'] = cod.fit_transform(targetEncode['repeater'])\n","  \n","  return trainData, testData, target, targetT, trainEncode, testEncode, targetEncode\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Qa_-hy1Zgqvt"},"source":["Transform into DATA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0LW5OpjUCUeJ"},"outputs":[],"source":["trainData, testData, target, targetT, trainEncode, testEncode, targetEncode \\\n"," = generateFeature(offers, transactions, trainhistory, testhistory)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":169,"status":"ok","timestamp":1680803820422,"user":{"displayName":"Hc c","userId":"00559738803274000756"},"user_tz":-480},"id":"4uBnks6Dd9LD","outputId":"39e4fb13-84c2-4b6d-e660-f9aac646a467"},"outputs":[{"data":{"text/plain":["(159700, 109)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["trainData.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00RZWKXliZGP"},"outputs":[],"source":["for i in trainData.columns :\n","  print('\"' + i + '\", ')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PTXPzHCDgg6K"},"source":["Standardization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2MsDYHuEYyc"},"outputs":[],"source":["select = [\n","    \"buy_total_freq\", \n","    \"buy_total_amount\", \n","    \"buy_total_avgamount\", \n","    \"buy_total_quantity\", \n","    \"buy_total_amount_30\", \n","    \"buy_total_quantity_30\", \n","    \"buy_total_freq_30\", \n","    \"buy_total_amount_60\", \n","    \"buy_total_quantity_60\", \n","    \"buy_total_freq_60\", \n","    \"buy_total_amount_90\", \n","    \"buy_total_quantity_90\", \n","    \"buy_total_freq_90\", \n","    \"buy_total_amount_120\", \n","    \"buy_total_quantity_120\", \n","    \"buy_total_freq_120\", \n","    \"buy_total_amount_150\", \n","    \"buy_total_quantity_150\", \n","    \"buy_total_freq_150\", \n","    \"buy_total_amount_180\", \n","    \"buy_total_quantity_180\", \n","    \"buy_total_freq_180\", \n","    \"buy_company_freq\", \n","    \"buy_company_amount\", \n","    \"buy_company_avgamount\", \n","    \"buy_company_quantity\", \n","    \"buy_brand_freq\", \n","    \"buy_brand_amount\", \n","    \"buy_brand_avgamount\", \n","    \"buy_brand_quantity\", \n","    \"buy_category_freq\", \n","    \"buy_category_amount\", \n","    \"buy_category_avgamount\", \n","    \"buy_category_quantity\", \n","    \"buy_company_amount_30\", \n","    \"buy_company_quantity_30\", \n","    \"buy_company_freq_30\", \n","    \"buy_brand_amount_30\", \n","    \"buy_brand_quantity_30\", \n","    \"buy_brand_freq_30\", \n","    \"buy_category_amount_30\", \n","    \"buy_category_quantity_30\", \n","    \"buy_category_freq_30\", \n","    \"buy_company_amount_60\", \n","    \"buy_company_quantity_60\", \n","    \"buy_company_freq_60\", \n","    \"buy_brand_amount_60\", \n","    \"buy_brand_quantity_60\", \n","    \"buy_brand_freq_60\", \n","    \"buy_category_amount_60\", \n","    \"buy_category_quantity_60\", \n","    \"buy_category_freq_60\", \n","    \"buy_company_amount_90\", \n","    \"buy_company_quantity_90\", \n","    \"buy_company_freq_90\", \n","    \"buy_brand_amount_90\", \n","    \"buy_brand_quantity_90\", \n","    \"buy_brand_freq_90\", \n","    \"buy_category_amount_90\", \n","    \"buy_category_quantity_90\", \n","    \"buy_category_freq_90\", \n","    \"buy_company_amount_120\", \n","    \"buy_company_quantity_120\", \n","    \"buy_company_freq_120\", \n","    \"buy_brand_amount_120\", \n","    \"buy_brand_quantity_120\", \n","    \"buy_brand_freq_120\", \n","    \"buy_category_amount_120\", \n","    \"buy_category_quantity_120\", \n","    \"buy_category_freq_120\", \n","    \"buy_company_amount_150\", \n","    \"buy_company_quantity_150\", \n","    \"buy_company_freq_150\", \n","    \"buy_brand_amount_150\", \n","    \"buy_brand_quantity_150\", \n","    \"buy_brand_freq_150\", \n","    \"buy_category_amount_150\", \n","    \"buy_category_quantity_150\", \n","    \"buy_category_freq_150\", \n","    \"buy_company_amount_180\", \n","    \"buy_company_quantity_180\", \n","    \"buy_company_freq_180\", \n","    \"buy_brand_amount_180\", \n","    \"buy_brand_quantity_180\", \n","    \"buy_brand_freq_180\", \n","    \"buy_category_amount_180\", \n","    \"buy_category_quantity_180\", \n","    \"buy_category_freq_180\", \n","    \"buy_company_brand_category_freq\", \n","    \"buy_company_brand_freq\", \n","    \"buy_company_category_freq\", \n","    \"buy_brand_category_freq\", \n","    \"buy_company_daydiff\", \n","    \"buy_brand_daydiff\", \n","    \"buy_category_daydiff\", \n","    \"buy_total_daydiff\"\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iF_hxsO1ClIU"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","trainStd = trainEncode.copy()\n","X = trainEncode[select]\n","scaler = StandardScaler()\n","trainStd[select] = scaler.fit_transform(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"82zkXgtTFrbk"},"outputs":[],"source":["testStd = testEncode.copy()\n","X = testEncode[select]\n","scaler = StandardScaler()\n","testStd[select] = scaler.fit_transform(X)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Xu-e73HwNzdB"},"source":["Generate Encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1mu1Ir1zDXik"},"outputs":[],"source":["target.to_csv('/content/drive/MyDrive/1經濟學/專題/featureNew/target.csv')\n","targetT.to_csv('/content/drive/MyDrive/1經濟學/專題/featureNew/targetTrips.csv')\n","trainData.to_csv('/content/drive/MyDrive/1經濟學/專題/featureNew/trainOriginal.csv')\n","testData.to_csv('/content/drive/MyDrive/1經濟學/專題/featureNew/testOriginal.csv')\n","trainEncode.to_csv('/content/drive/MyDrive/1經濟學/專題/featureNew/trainEncode.csv')\n","testEncode.to_csv('/content/drive/MyDrive/1經濟學/專題/featureNew/testEncode.csv')\n","targetEncode.to_csv('/content/drive/MyDrive/1經濟學/專題/featureNew/targetEncode.csv')\n","trainStd.to_csv('/content/drive/MyDrive/1經濟學/專題/featureNew/trainStd.csv')\n","testStd.to_csv('/content/drive/MyDrive/1經濟學/專題/featureNew/testStd.csv')"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
