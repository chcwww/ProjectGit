{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "offers = pd.read_csv(r'C:\\\\Users\\\\chcww\\\\Downloads\\\\offers.csv')\n",
    "transactions = pd.read_csv(r'C:\\\\Users\\\\chcww\\\\Downloads\\\\newdata.csv')\n",
    "trainHistory = pd.read_csv(r'C:\\\\Users\\\\chcww\\\\Downloads\\\\trainHistory.csv')\n",
    "testHistory = pd.read_csv(r'C:\\\\Users\\\\chcww\\\\Downloads\\\\testHistory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "offertry = pd.read_csv(r'C:\\\\Users\\\\chcww\\\\Downloads\\\\offers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['offer', 'category', 'quantity', 'company', 'offervalue', 'brand'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offertry.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "offertry.rename(columns = {'offer' : '12', 'category' : '132', 'quantity' : '1232', \n",
    "                           'company' : '125232', 'offervalue' : '12352', 'brand' : '12332'}, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, 10000, None),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\python_venv\\ML_pratice\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\python_venv\\ML_pratice\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\python_venv\\ML_pratice\\lib\\site-packages\\pandas\\_libs\\index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, 10000, None),)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(trainHistory, offers, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39moffer\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(train, transactions, on\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m)[:\u001b[39m10000\u001b[39;49m,]\n\u001b[0;32m      4\u001b[0m test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(testHistory, offers, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39moffer\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(test, transactions, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m)[:\u001b[39m10000\u001b[39m,]\n",
      "File \u001b[1;32mc:\\python_venv\\ML_pratice\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\python_venv\\ML_pratice\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3804\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m         \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m         \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m         \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3809\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[0;32m   3810\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m \u001b[39m# GH#42269\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python_venv\\ML_pratice\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5925\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5921\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   5922\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5923\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5924\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5925\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, 10000, None),)"
     ]
    }
   ],
   "source": [
    "train = pd.merge(trainHistory, offers, on='offer')\n",
    "train = pd.merge(train, transactions, on='id')[:10000,]\n",
    "\n",
    "test = pd.merge(testHistory, offers, on='offer')\n",
    "test = pd.merge(test, transactions, on='id')[:10000,]\n",
    "\n",
    "data = pd.concat([train, test], axis=0, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Offer One-Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainOffer = trainHistory[['offer', 'id']]\n",
    "trainOneHot = pd.get_dummies(trainOffer, columns = ['offer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "features = ['chain', 'offer', 'market', 'category', 'company', 'brand', 'productsize', 'productmeasure', 'purchasequantity', 'purchaseamount']\n",
    "\n",
    "# Feature engineering\n",
    "# 1. Group the data by customer and offer, and calculate aggregate features\n",
    "grouped = data.groupby(['id', 'offer']).agg({\n",
    "    'market': 'first',\n",
    "    'productsize': 'first',\n",
    "    'productmeasure': 'first',\n",
    "    'quantity': 'sum',\n",
    "    'offervalue': 'first'\n",
    "})\n",
    "\n",
    "# Rename columns\n",
    "grouped.columns = ['market', 'productsize', 'productmeasure', 'totalquantity', 'offervalue']\n",
    "\n",
    "# Reset index to make customer and offer into separate columns\n",
    "grouped = grouped.reset_index()\n",
    "\n",
    "# 2. Calculate additional features\n",
    "# a) Average transaction amount for each customer\n",
    "avg_transaction_amount = data.groupby(['id'])['purchaseamount'].mean().reset_index()\n",
    "avg_transaction_amount.columns = ['id', 'avg_transaction_amount']\n",
    "grouped = pd.merge(grouped, avg_transaction_amount, on='id')\n",
    "\n",
    "\n",
    "\n",
    "#calculate additional features average transaction amount for each customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# b) Total amount spent by each customer\n",
    "total_amount_spent = data.groupby(['id'])['purchaseamount'].sum().reset_index()\n",
    "total_amount_spent.columns = ['id', 'total_amount_spent']\n",
    "grouped = pd.merge(grouped, total_amount_spent, on='id')\n",
    "\n",
    "# c) Number of offers used by each customer\n",
    "num_offers_used = data.groupby(['id'])['offer'].nunique().reset_index()\n",
    "num_offers_used.columns = ['id', 'num_offers_used']\n",
    "grouped = pd.merge(grouped, num_offers_used, on='id')\n",
    "\n",
    "# d) Total number of transactions by each customer\n",
    "num_transactions = data.groupby(['id'])['transacted'].count().reset_index()\n",
    "num_transactions.columns = ['id', 'num_transactions']\n",
    "grouped = pd.merge(grouped, num_transactions, on='id')\n",
    "\n",
    "# e) Average quantity purchased by each customer\n",
    "avg_quantity = data.groupby(['id'])['quantity'].mean().reset_index()\n",
    "avg_quantity.columns = ['id', 'avg_quantity']\n",
    "grouped = pd.merge(grouped, avg_quantity, on='id')\n",
    "\n",
    "# f) Total quantity purchased by each customer\n",
    "total_quantity = data.groupby(['id'])['quantity'].sum().reset_index()\n",
    "total_quantity.columns = ['id', 'total_quantity']\n",
    "grouped = pd.merge(grouped, total_quantity, on='id')\n",
    "\n",
    "# Split the data back into train and test sets\n",
    "train_data = grouped[grouped['offer'].isin(trainHistory['offer'])]\n",
    "test_data = grouped[grouped['offer'].isin(testHistory['offer'])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_pratice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f472db67bec261ea869d02f15ae560da63e32d32ea2e8fe3fd8a711c77b64d1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
